{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random \n",
    "import string \n",
    "import nipype.interfaces.io as nio \n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util \n",
    "import matplotlib.pylab as plt \n",
    "import nibabel as nb\n",
    "import numpy as np \n",
    "\n",
    "from os.path import abspath \n",
    "from nipype import Workflow, Node, MapNode, Function \n",
    "from nipype.interfaces.fsl import BET, FLIRT, FNIRT, FAST, ApplyWarp, ExtractROI, GLM, Threshold, ErodeImage, ApplyMask, FEAT\n",
    "from nipype.interfaces.spm import SliceTiming, Realign, Coregister, Normalize, Smooth, Segment, ApplyTransform, Level1Design\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.interfaces.base import Undefined\n",
    "from nipype.utils.filemanip import filename_to_list\n",
    "from nilearn.plotting import plot_anat\n",
    "from nipype.interfaces import IdentityInterface\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "from nilearn.signal import clean \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Motion_reg_creator(motion_params, outliers, N_motion_reg=12):\n",
    "    import numpy as np \n",
    "    motpar = np.loadtxt(motion_params, \n",
    "                   dtype='f')\n",
    "    out = np.loadtxt(outliers, \n",
    "                   dtype='i')\n",
    "    \n",
    "    # Motion Regressors \n",
    "    if N_motion_reg == 6: \n",
    "        motion_reg = motpar\n",
    "    elif N_motion_reg == 12: \n",
    "        df = np.concatenate((np.zeros((1,6)), np.diff(motpar, axis=0)),axis=0)\n",
    "        motion_reg = np.concatenate((motpar,df), axis=1)\n",
    "    elif N_motion_reg == 24: \n",
    "        df = np.concatenate((np.zeros((1,6)), np.diff(motpar, axis=0)),axis=0)\n",
    "        motion_reg = np.concatenate((motpar, df, motpar**2, df**2), axis=1)\n",
    "        \n",
    "    # Outlier Regressors \n",
    "    if np.shape(out)[0] != 0:\n",
    "        out_reg = np.zeros((motpar.shape[0],1))\n",
    "        for i in range(len(out)): \n",
    "            tmpreg = np.zeros((motpar.shape[0],1))\n",
    "            tmpreg[out[i]] = 1 \n",
    "            out_reg = np.concatenate((out_reg, tmpreg), axis=1)\n",
    "        out_reg = out_reg[:,1:]\n",
    "        output = np.concatenate((motion_reg, out_reg), axis=1)\n",
    "        return output\n",
    "    else: \n",
    "        output = motion_reg\n",
    "        return output\n",
    "    \n",
    "def Design_Matrix(motion_reg, wmnoise_reg, csfnoise_reg):\n",
    "    import numpy as np \n",
    "    import string\n",
    "    import random\n",
    "    import os\n",
    "    wmnoise = np.loadtxt(wmnoise_reg, skiprows=1)\n",
    "    csfnoise = np.loadtxt(csfnoise_reg, skiprows=1)\n",
    "    out = np.concatenate((motion_reg, wmnoise, csfnoise), axis=1)\n",
    "    letters = string.ascii_lowercase\n",
    "    name = ''.join(random.choice(letters) for i in range(6))\n",
    "    folder_dir = '/tmp/tmp'+name\n",
    "    os.mkdir(folder_dir)\n",
    "    file_dir = folder_dir + '/DesMat.txt'\n",
    "    np.savetxt(file_dir, out)\n",
    "    return file_dir\n",
    "\n",
    "def bandpass_filter(signal, lowpass_freq, highpass_freq, fs):\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    out_files = []\n",
    "    img = nb.load(signal)\n",
    "    timepoints = img.shape[-1]\n",
    "    F = np.zeros((timepoints))\n",
    "    lowidx = int(timepoints / 2) + 1\n",
    "    if lowpass_freq > 0:\n",
    "        lowidx = np.round(lowpass_freq / fs * timepoints)\n",
    "    highidx = 0\n",
    "    if highpass_freq > 0:\n",
    "        highidx = np.round(highpass_freq / fs * timepoints)\n",
    "    F[int(highidx):int(lowidx)] = 1\n",
    "    F = ((F + F[::-1]) > 0).astype(int)\n",
    "    data = img.get_data()\n",
    "    if np.all(F == 1):\n",
    "        filtered_data = data\n",
    "    else:\n",
    "        filtered_data = np.real(np.fft.ifftn(np.fft.fftn(data) * F))\n",
    "    img_out = nb.Nifti1Image(filtered_data, img.affine, img.header)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/sepehr/Desktop/T1_pipeline\"\n",
    "out_dir = \"/home/sepehr/Desktop/T1_pipeline/preproc\"\n",
    "subject_list = ['s2']\n",
    "\n",
    "gm_prob = '/media/sepehr/d504ddce-3b3c-4271-a3f5-2c6dd4c230f3/Projects/GITLAB/mind_blanking/Codes/necessary_files/grey.nii'\n",
    "wm_prob = '/media/sepehr/d504ddce-3b3c-4271-a3f5-2c6dd4c230f3/Projects/GITLAB/mind_blanking/Codes/necessary_files/white.nii'\n",
    "csf_prob = '/media/sepehr/d504ddce-3b3c-4271-a3f5-2c6dd4c230f3/Projects/GITLAB/mind_blanking/Codes/necessary_files/csf.nii'\n",
    "\n",
    "MNI_template = \"/media/sepehr/d504ddce-3b3c-4271-a3f5-2c6dd4c230f3/Projects/GITLAB/mind_blanking/Codes/necessary_files/MNI152_T1_2mm_brain.nii\" \n",
    "\n",
    "# Functional Data Parameters\n",
    "\n",
    "Num_of_Slices = 32 \n",
    "TR = 2 \n",
    "TA = TR - TR/float(Num_of_Slices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dict(\n",
    "    func=[['subject_id', 'func']],\n",
    "    struct=[['subject_id', 'struct']])\n",
    "infosource = pe.Node(\n",
    "    interface=util.IdentityInterface(fields=['subject_id']), name=\"infosource\")\n",
    "infosource.iterables = ('subject_id', subject_list)\n",
    "\n",
    "datasource = pe.Node(interface=nio.DataGrabber(\n",
    "                     infields=['subject_id'], outfields=['func', 'struct']),\n",
    "                     name='datasource')\n",
    "datasource.inputs.base_directory = data_dir\n",
    "datasource.inputs.template = '%s/%s.nii'\n",
    "datasource.inputs.template_args = info\n",
    "datasource.inputs.sort_filelist = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline Nodes Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Volume Removal \n",
    "num_of_scans_rmv = 3\n",
    "VolRv = Node(ExtractROI(t_min=num_of_scans_rmv, t_size=-1, output_type='NIFTI'),\n",
    "               name=\"VolumeRemoval\")\n",
    "\n",
    "# Slice Time Correction \n",
    "SliceTimeCorr = Node(SliceTiming(), name=\"SliceTimeCorrection\")\n",
    "SliceTimeCorr.inputs.num_slices = Num_of_Slices  \n",
    "SliceTimeCorr.inputs.time_repetition = TR \n",
    "SliceTimeCorr.inputs.time_acquisition = TA \n",
    "SliceTimeCorr.inputs.slice_order = list(range(1,Num_of_Slices+1))\n",
    "SliceTimeCorr.inputs.ref_slice = 1 \n",
    "\n",
    "# Realignment of functional data \n",
    "ReAlign = Node(Realign(), name=\"Realignment\")\n",
    "ReAlign.inputs.quality = 0.9\n",
    "ReAlign.inputs.fwhm = 5\n",
    "ReAlign.inputs.separation = 4 \n",
    "ReAlign.inputs.register_to_mean = True \n",
    "ReAlign.inputs.interp = 2\n",
    "ReAlign.inputs.write_interp = 4\n",
    "ReAlign.inputs.write_mask = True \n",
    "\n",
    "# ART Artifact Detection \n",
    "Art = Node(ArtifactDetect(), name=\"ArtifactDetection\")\n",
    "Art.inputs.parameter_source = 'SPM'\n",
    "Art.inputs.use_norm = Undefined\n",
    "Art.inputs.rotation_threshold = 0.05\n",
    "Art.inputs.translation_threshold = 4 \n",
    "Art.inputs.zintensity_threshold = 3\n",
    "Art.inputs.mask_type = 'spm_global'\n",
    "Art.inputs.save_plot = True \n",
    "\n",
    "# Coregistration of functional data to structural data in native space \n",
    "CoReg = Node(Coregister(), name='Coregistration')\n",
    "CoReg.inputs.cost_function = 'nmi'\n",
    "CoReg.inputs.separation = [4, 2]\n",
    "CoReg.inputs.tolerance = [0.02, 0.02, 0.02, \n",
    "                          0.001, 0.001, 0.001, \n",
    "                          0.01, 0.01, 0.01, \n",
    "                          0.001, 0.001, 0.001]\n",
    "\n",
    "# Brain Extraction \n",
    "Bet = Node(BET(), name='BrainExtraction')\n",
    "Bet.inputs.mask = True \n",
    "Bet.inputs.frac = 0.3 \n",
    "Bet.inputs.output_type = 'NIFTI'\n",
    "\n",
    "# Segmentation of Structural Data \n",
    "Seg = Node(Segment(), name='Segmentation')\n",
    "Seg.inputs.gm_output_type = [False, True, True] #Native + unmodulated normalized\n",
    "Seg.inputs.wm_output_type = [False, True, True] #Native + unmodulated normalized\n",
    "Seg.inputs.csf_output_type = [False, True, True] #Native + unmodulated normalized\n",
    "Seg.inputs.save_bias_corrected = True \n",
    "Seg.inputs.clean_masks = 'no'\n",
    "Seg.inputs.tissue_prob_maps=[gm_prob, wm_prob, csf_prob]\n",
    "Seg.inputs.gaussians_per_class = [2, 2, 2, 4]\n",
    "Seg.inputs.affine_regularization = 'mni' \n",
    "Seg.inputs.warping_regularization = 1 \n",
    "Seg.inputs.warp_frequency_cutoff = 25 \n",
    "Seg.inputs.bias_regularization = 0.0001\n",
    "Seg.inputs.bias_fwhm = 60 \n",
    "Seg.inputs.sampling_distance = 3 \n",
    "\n",
    "# Thresholding Probability Maps to Create Binary Masks \n",
    "gmth = Node(Threshold(), name='GMBinaryMask')\n",
    "gmth.inputs.thresh = 0.5 \n",
    "gmth.inputs.args = '-bin'\n",
    "gmth.inputs.output_type = 'NIFTI'\n",
    "\n",
    "wmth = Node(Threshold(), name='WMBinaryMask')\n",
    "wmth.inputs.thresh = 0.5 \n",
    "wmth.inputs.args = '-bin'\n",
    "wmth.inputs.output_type = 'NIFTI'\n",
    "\n",
    "csfth = Node(Threshold(), name='CSFBinaryMask')\n",
    "csfth.inputs.thresh = 0.5 \n",
    "csfth.inputs.args = '-bin'\n",
    "csfth.inputs.output_type = 'NIFTI'\n",
    "\n",
    "# Erosion of WM Mask \n",
    "erwm = Node(ErodeImage(), name='ErosionWM')\n",
    "erwm.inputs.kernel_shape = '3D'\n",
    "erwm.inputs.output_type = 'NIFTI'\n",
    "\n",
    "# Erosion of CSF Mask \n",
    "ercsf = Node(ErodeImage(), name='ErosionCSF')\n",
    "ercsf.inputs.kernel_shape = '3D'\n",
    "ercsf.inputs.output_type = 'NIFTI'\n",
    "\n",
    "# Normalization of Structural and Functional Image to MNI Space \n",
    "Norm = Node(Normalize(), name=\"Normalization\")\n",
    "Norm.inputs.template = MNI_template\n",
    "\n",
    "# Normalization of Structural and GM Mask to MNI Space \n",
    "Normgm = Node(Normalize(), name=\"NormalizationGM\")\n",
    "Normgm.inputs.template = MNI_template\n",
    "\n",
    "# Normalization of Structural and WM Mask to MNI Space \n",
    "Normwm = Node(Normalize(), name=\"NormalizationWM\")\n",
    "Normwm.inputs.template = MNI_template\n",
    "\n",
    "# Normalization of Structural and CSF Mask to MNI Space \n",
    "Normcsf = Node(Normalize(), name=\"NormalizationCSF\")\n",
    "Normcsf.inputs.template = MNI_template\n",
    "\n",
    "# Normalization of Structural and Brain Mask to MNI Space \n",
    "Normmask = Node(Normalize(), name=\"NormalizationMask\")\n",
    "Normmask.inputs.template = MNI_template\n",
    "\n",
    "# Functional Data Smooting \n",
    "Smth = Node(Smooth(), name='Smoothing')\n",
    "Smth.inputs.fwhm = [6, 6, 6]\n",
    "Smth.inputs.implicit_masking = False \n",
    "\n",
    "# WM and CSF Noise Components \n",
    "WMnoise = Node(CompCor(), name='WM_Noise_Regressors')\n",
    "CSFnoise = Node(CompCor(), name='CSF_Noise_Regressors')\n",
    "WMnoise.inputs.repetition_time = TR\n",
    "CSFnoise.inputs.repetition_time = TR\n",
    "WMnoise.inputs.num_components = 5\n",
    "CSFnoise.inputs.num_components = 5\n",
    "\n",
    "# Motion and Outlier Regressors\n",
    "Mot = Node(Function(input_names=['motion_params', 'outliers', 'N_motion_reg'], \n",
    "                   output_names=['output'], function=Motion_reg_creator), name='Motion_Reg_Creator')\n",
    "\n",
    "# Create Design Matrix \n",
    "DesMat = Node(Function(input_names=['motion_reg', 'wmnoise_reg', 'csfnoise_reg', 'drift'],\n",
    "                      output_names=['file_dir'], function=Design_Matrix), name='Design_Matrix_Gen')\n",
    "\n",
    "# Perform GLM \n",
    "glm = Node(GLM(), name='GLM')\n",
    "glm.inputs.out_res_name = 'glm_res.nii'\n",
    "glm.inputs.output_type = 'NIFTI'\n",
    "glm.inputs.demean = True \n",
    "glm.inputs.des_norm = True \n",
    "\n",
    "\n",
    "# Filtering \n",
    "bpf = Node(Function(input_names=['signal', 'lowpass_freq', 'highpass_freq', 'fs'], \n",
    "                   output_names=['img_out'], function=bandpass_filter), name='BPF')\n",
    "bpf.inputs.lowpass_freq = 0.008\n",
    "bpf.inputs.highpass_freq = 0.09\n",
    "bpf.inputs.fs = 1/float(TR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs Storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasink = pe.Node(interface=nio.DataSink(), name=\"datasink\")\n",
    "datasink.inputs.base_directory = os.path.abspath(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200630-09:46:48,42 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /media/sepehr/d504ddce-3b3c-4271-a3f5-2c6dd4c230f3/Projects/GITLAB/mind_blanking/Results/preproc_pipeline/Preproc_Pipeline.png (graph2use=orig, simple_form=True).\n",
      "200630-09:46:48,609 nipype.workflow INFO:\n",
      "\t Generated workflow graph: ../../Results/preproc_pipeline/Preproc_Pipeline_col.png (graph2use=colored, simple_form=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../Results/preproc_pipeline/Preproc_Pipeline_col.png'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc = Workflow(name='pipeline')\n",
    "\n",
    "preproc.connect([\n",
    "    (infosource   , datasource,    [('subject_id', 'subject_id')]),\n",
    "    (datasource   , VolRv,         [('func', 'in_file')]),\n",
    "    (datasource   , Bet,           [('struct', 'in_file')]),\n",
    "    (Bet          , Seg,           [('out_file', 'data')]),\n",
    "    (Bet          , Seg,           [('mask_file', 'mask_image')]),\n",
    "    (Seg          , Norm,          [('bias_corrected_image','source')]),\n",
    "    (Seg          , Normgm,        [('bias_corrected_image','source')]),\n",
    "    (Seg          , Normwm,        [('bias_corrected_image','source')]),\n",
    "    (Seg          , Normcsf,       [('bias_corrected_image','source')]),\n",
    "    (Seg          , Normmask,      [('bias_corrected_image','source')]),\n",
    "    (CoReg        , Norm,          [('coregistered_files', 'apply_to_files')]),\n",
    "    (Seg          , Normgm,        [('native_gm_image', 'apply_to_files')]),\n",
    "    (Seg          , Normwm,        [('native_wm_image', 'apply_to_files')]),\n",
    "    (Seg          , Normcsf,       [('native_csf_image', 'apply_to_files')]),\n",
    "    (Bet          , Normmask,      [('mask_file', 'apply_to_files')]),\n",
    "    (Norm         , Smth,          [('normalized_files', 'in_files')]),\n",
    "    (VolRv        , SliceTimeCorr, [('roi_file', 'in_files')]),\n",
    "    (SliceTimeCorr, ReAlign,       [('timecorrected_files', 'in_files')]),\n",
    "    (ReAlign      , Art,           [('realigned_files', 'realigned_files'),\n",
    "                                    ('realignment_parameters', 'realignment_parameters')]),\n",
    "    (ReAlign      , CoReg,         [('mean_image', 'source'), \n",
    "                                    ('realigned_files', 'apply_to_files')]),\n",
    "    (Seg          , CoReg,         [('bias_corrected_image', 'target')]),\n",
    "    (Normgm       , gmth,          [('normalized_files', 'in_file')]),\n",
    "    (Normwm       , wmth,          [('normalized_files', 'in_file')]),\n",
    "    (Normcsf      , csfth,         [('normalized_files', 'in_file')]),\n",
    "    (wmth         , erwm,          [('out_file', 'in_file')]),\n",
    "    (csfth        , ercsf,         [('out_file', 'in_file')]),\n",
    "    (erwm         , WMnoise,       [('out_file', 'mask_files')]),\n",
    "    (ercsf        , CSFnoise,      [('out_file', 'mask_files')]),\n",
    "    (Norm         , WMnoise,       [('normalized_files', 'realigned_file')]),\n",
    "    (Norm         , CSFnoise,      [('normalized_files', 'realigned_file')]),\n",
    "    (ReAlign      , Mot,           [('realignment_parameters', 'motion_params')]), \n",
    "    (Art          , Mot,           [('outlier_files', 'outliers')]),\n",
    "    (Mot          , DesMat,        [('output', 'motion_reg')]),\n",
    "    (WMnoise      , DesMat,        [('components_file', 'wmnoise_reg')]),\n",
    "    (CSFnoise     , DesMat,        [('components_file', 'csfnoise_reg')]),\n",
    "    (DesMat       , glm,           [('file_dir', 'design')]),\n",
    "    (Smth         , glm,           [('smoothed_files', 'in_file')]),\n",
    "    (Normmask     , glm,           [('normalized_files', 'mask')]),\n",
    "    (glm          , bpf,           [('out_res', 'signal')]),\n",
    "    ##################################################################################################\n",
    "    (infosource   , datasink,      [('subject_id', 'container')]),\n",
    "    (ReAlign      , datasink,      [('mean_image', 'ReAlign.@mean'),\n",
    "                                    ('realignment_parameters', 'ReAlign.@param'),\n",
    "                                    ('realigned_files', 'ReAlign.@RA_files')]),\n",
    "    (CoReg        , datasink,      [('coregistered_files', 'CoReg.@coreg')]), \n",
    "    (Bet          , datasink,      [('out_file','BET.@brain'), \n",
    "                                    ('mask_file', 'BET.@brain_mask')]),\n",
    "    (Seg          , datasink,      [('native_gm_image', 'Segment.@GM'),\n",
    "                                    ('native_wm_image', 'Segment.@WM'),\n",
    "                                    ('native_csf_image', 'Segment.@CSF'), \n",
    "                                    ('bias_corrected_image', 'Segment.@Bias_Corrected')]),\n",
    "    (Norm         , datasink,      [('normalized_source', 'Normalization.@StrctNorm'),\n",
    "                                    ('normalization_parameters', 'Normalization.@Norm_Param'), \n",
    "                                    ('normalized_files', 'Normalization.@FcNorm')]),\n",
    "    (Normgm       , datasink,      [('normalized_files', 'Normalization.@GMNorm')]),\n",
    "    (Normwm       , datasink,      [('normalized_files', 'Normalization.@WMNorm')]),\n",
    "    (Normcsf      , datasink,      [('normalized_files', 'Normalization.@CSFNorm')]),\n",
    "    (Normmask     , datasink,      [('normalized_files', 'Normalization.@MaskNorm')]),\n",
    "    (gmth         , datasink,      [('out_file', 'Normalization.@GMMask')]),\n",
    "    (wmth         , datasink,      [('out_file', 'Normalization.@WMMask')]),\n",
    "    (csfth        , datasink,      [('out_file', 'Normalization.@CSFMask')]),\n",
    "    (erwm         , datasink,      [('out_file', 'Normalization.@WMMask_er')]),\n",
    "    (ercsf        , datasink,      [('out_file', 'Normalization.@CSFMask_er')]),\n",
    "    (Smth         , datasink,      [('smoothed_files', 'Smoothing.@Smoothed')]), \n",
    "    (Art          , datasink,      [('outlier_files', 'ART.@Outliers'), \n",
    "                                    ('plot_files', 'ART.@Outliers_img'), \n",
    "                                    ('displacement_files', 'ART.@Displacement')]),\n",
    "    (DesMat       , datasink,      [('file_dir', 'DesignMatrix.@DesMat')]),\n",
    "    (glm          , datasink,      [('out_res', 'GLM_Results.@residuals')]),\n",
    "    (bpf          , datasink,      [('img_out', 'BandPassFiltered.@final')])\n",
    "])\n",
    "# Visualize the detailed graph\n",
    "preproc.write_graph(graph2use='orig', format='png', simple_form=True, \n",
    "                    dotfilename='../../Results/preproc_pipeline/Preproc_Pipeline.dot')\n",
    "preproc.write_graph(graph2use='colored', format='png', simple_form=True, \n",
    "                    dotfilename='../../Results/preproc_pipeline/Preproc_Pipeline_col.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200630-09:46:57,890 nipype.workflow INFO:\n",
      "\t Workflow pipeline settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "200630-09:46:57,918 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "200630-09:46:57,921 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 13.98/13.98, Free processors: 8/8.\n",
      "200630-09:46:58,330 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.datasource\" in \"/tmp/tmp48__b5uj/pipeline/_subject_id_s2/datasource\".\n",
      "200630-09:46:58,336 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "200630-09:46:58,342 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.datasource\".\n",
      "200630-09:46:59,929 nipype.workflow INFO:\n",
      "\t [Job 0] Completed (pipeline.datasource).\n",
      "200630-09:46:59,940 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 13.98/13.98, Free processors: 8/8.\n",
      "200630-09:47:00,355 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.VolumeRemoval\" in \"/tmp/tmph1btxqc9/pipeline/_subject_id_s2/VolumeRemoval\".\n",
      "200630-09:47:00,355 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.BrainExtraction\" in \"/tmp/tmpq7whpkwu/pipeline/_subject_id_s2/BrainExtraction\".\n",
      "200630-09:47:00,366 nipype.workflow INFO:\n",
      "\t [Node] Running \"VolumeRemoval\" (\"nipype.interfaces.fsl.utils.ExtractROI\"), a CommandLine Interface with command:\n",
      "fslroi /home/sepehr/Desktop/T1_pipeline/s2/func.nii /tmp/tmph1btxqc9/pipeline/_subject_id_s2/VolumeRemoval/func_roi.nii 3 -1\n",
      "200630-09:47:00,369 nipype.workflow INFO:\n",
      "\t [Node] Running \"BrainExtraction\" (\"nipype.interfaces.fsl.preprocess.BET\"), a CommandLine Interface with command:\n",
      "bet /home/sepehr/Desktop/T1_pipeline/s2/struct.nii /tmp/tmpq7whpkwu/pipeline/_subject_id_s2/BrainExtraction/struct_brain.nii -f 0.30 -m\n",
      "200630-09:47:01,659 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.VolumeRemoval\".\n",
      "200630-09:47:01,924 nipype.workflow INFO:\n",
      "\t [Job 12] Completed (pipeline.VolumeRemoval).\n",
      "200630-09:47:01,926 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.BrainExtraction\n",
      "200630-09:47:02,226 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.SliceTimeCorrection\" in \"/tmp/tmpbz3vh7vl/pipeline/_subject_id_s2/SliceTimeCorrection\".\n",
      "200630-09:47:02,234 nipype.workflow INFO:\n",
      "\t [Node] Running \"SliceTimeCorrection\" (\"nipype.interfaces.spm.preprocess.SliceTiming\")\n",
      "200630-09:47:03,156 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.BrainExtraction\".\n",
      "200630-09:47:03,926 nipype.workflow INFO:\n",
      "\t [Job 1] Completed (pipeline.BrainExtraction).\n",
      "200630-09:47:03,929 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.SliceTimeCorrection\n",
      "200630-09:47:04,217 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.Segmentation\" in \"/tmp/tmpkd0z29kw/pipeline/_subject_id_s2/Segmentation\".\n",
      "200630-09:47:04,229 nipype.workflow INFO:\n",
      "\t [Node] Running \"Segmentation\" (\"nipype.interfaces.spm.preprocess.Segment\")\n",
      "200630-09:47:05,928 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 13.58/13.98, Free processors: 6/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Segmentation\n",
      "                       * pipeline.SliceTimeCorrection\n",
      "200630-09:47:31,664 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.SliceTimeCorrection\".\n",
      "200630-09:47:31,948 nipype.workflow INFO:\n",
      "\t [Job 13] Completed (pipeline.SliceTimeCorrection).\n",
      "200630-09:47:31,951 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Segmentation\n",
      "200630-09:47:32,266 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.Realignment\" in \"/tmp/tmpklgi2div/pipeline/_subject_id_s2/Realignment\".\n",
      "200630-09:47:32,355 nipype.workflow INFO:\n",
      "\t [Node] Running \"Realignment\" (\"nipype.interfaces.spm.preprocess.Realign\")\n",
      "200630-09:47:33,951 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 13.58/13.98, Free processors: 6/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Realignment\n",
      "                       * pipeline.Segmentation\n",
      "200630-09:48:18,177 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.Segmentation\".\n",
      "200630-09:48:19,989 nipype.workflow INFO:\n",
      "\t [Job 2] Completed (pipeline.Segmentation).\n",
      "200630-09:48:19,991 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 4 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Realignment\n",
      "200630-09:48:20,278 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.NormalizationWM\" in \"/tmp/tmp4j2874_8/pipeline/_subject_id_s2/NormalizationWM\".\n",
      "200630-09:48:20,278 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.NormalizationMask\" in \"/tmp/tmpml44z_7u/pipeline/_subject_id_s2/NormalizationMask\".\n",
      "200630-09:48:20,279 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.NormalizationGM\" in \"/tmp/tmphgamt5g2/pipeline/_subject_id_s2/NormalizationGM\".\n",
      "200630-09:48:20,278 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.NormalizationCSF\" in \"/tmp/tmpih9t49ip/pipeline/_subject_id_s2/NormalizationCSF\".\n",
      "200630-09:48:20,336 nipype.workflow INFO:\n",
      "\t [Node] Running \"NormalizationGM\" (\"nipype.interfaces.spm.preprocess.Normalize\")\n",
      "200630-09:48:20,343 nipype.workflow INFO:\n",
      "\t [Node] Running \"NormalizationMask\" (\"nipype.interfaces.spm.preprocess.Normalize\")\n",
      "200630-09:48:20,348 nipype.workflow INFO:\n",
      "\t [Node] Running \"NormalizationWM\" (\"nipype.interfaces.spm.preprocess.Normalize\")\n",
      "200630-09:48:20,350 nipype.workflow INFO:\n",
      "\t [Node] Running \"NormalizationCSF\" (\"nipype.interfaces.spm.preprocess.Normalize\")\n",
      "200630-09:48:21,992 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 5 tasks, and 0 jobs ready. Free memory (GB): 12.98/13.98, Free processors: 3/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.NormalizationGM\n",
      "                       * pipeline.NormalizationWM\n",
      "                       * pipeline.NormalizationCSF\n",
      "                       * pipeline.NormalizationMask\n",
      "                       * pipeline.Realignment\n",
      "200630-09:48:26,490 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.Realignment\".\n",
      "200630-09:48:27,996 nipype.workflow INFO:\n",
      "\t [Job 14] Completed (pipeline.Realignment).\n",
      "200630-09:48:28,0 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 4 tasks, and 2 jobs ready. Free memory (GB): 13.18/13.98, Free processors: 4/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.NormalizationGM\n",
      "                       * pipeline.NormalizationWM\n",
      "                       * pipeline.NormalizationCSF\n",
      "                       * pipeline.NormalizationMask\n",
      "200630-09:48:28,448 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.Coregistration\" in \"/tmp/tmpmti2eg42/pipeline/_subject_id_s2/Coregistration\".\n",
      "200630-09:48:28,448 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.ArtifactDetection\" in \"/tmp/tmpwwi2sd3r/pipeline/_subject_id_s2/ArtifactDetection\".\n",
      "200630-09:48:28,461 nipype.workflow INFO:\n",
      "\t [Node] Running \"ArtifactDetection\" (\"nipype.algorithms.rapidart.ArtifactDetect\")\n",
      "200630-09:48:29,388 nipype.workflow INFO:\n",
      "\t [Node] Running \"Coregistration\" (\"nipype.interfaces.spm.preprocess.Coregister\")\n",
      "200630-09:48:29,764 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.ArtifactDetection\".\n",
      "200630-09:48:29,997 nipype.workflow INFO:\n",
      "\t [Job 20] Completed (pipeline.ArtifactDetection).\n",
      "200630-09:48:30,1 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 5 tasks, and 1 jobs ready. Free memory (GB): 12.98/13.98, Free processors: 3/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Coregistration\n",
      "                       * pipeline.NormalizationGM\n",
      "                       * pipeline.NormalizationWM\n",
      "                       * pipeline.NormalizationCSF\n",
      "                       * pipeline.NormalizationMask\n",
      "200630-09:48:30,446 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.Motion_Reg_Creator\" in \"/tmp/tmprfnfdypr/pipeline/_subject_id_s2/Motion_Reg_Creator\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200630-09:48:30,460 nipype.workflow INFO:\n",
      "\t [Node] Running \"Motion_Reg_Creator\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: UserWarning: loadtxt: Empty input file: \"/tmp/tmpwwi2sd3r/pipeline/_subject_id_s2/ArtifactDetection/art.rafunc_roi_outliers.txt\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200630-09:48:30,503 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.Motion_Reg_Creator\".\n",
      "200630-09:48:31,999 nipype.workflow INFO:\n",
      "\t [Job 21] Completed (pipeline.Motion_Reg_Creator).\n",
      "200630-09:48:32,3 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 5 tasks, and 0 jobs ready. Free memory (GB): 12.98/13.98, Free processors: 3/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Coregistration\n",
      "                       * pipeline.NormalizationGM\n",
      "                       * pipeline.NormalizationWM\n",
      "                       * pipeline.NormalizationCSF\n",
      "                       * pipeline.NormalizationMask\n",
      "200630-09:48:51,535 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.NormalizationGM\".\n",
      "200630-09:48:51,848 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.NormalizationMask\".\n",
      "200630-09:48:52,14 nipype.workflow INFO:\n",
      "\t [Job 3] Completed (pipeline.NormalizationMask).\n",
      "200630-09:48:52,16 nipype.workflow INFO:\n",
      "\t [Job 10] Completed (pipeline.NormalizationGM).\n",
      "200630-09:48:52,19 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 3 tasks, and 1 jobs ready. Free memory (GB): 13.38/13.98, Free processors: 5/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Coregistration\n",
      "                       * pipeline.NormalizationWM\n",
      "                       * pipeline.NormalizationCSF\n",
      "200630-09:48:52,382 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.GMBinaryMask\" in \"/tmp/tmpacrk_dhy/pipeline/_subject_id_s2/GMBinaryMask\".\n",
      "200630-09:48:52,393 nipype.workflow INFO:\n",
      "\t [Node] Running \"GMBinaryMask\" (\"nipype.interfaces.fsl.maths.Threshold\"), a CommandLine Interface with command:\n",
      "fslmaths /tmp/tmphgamt5g2/pipeline/_subject_id_s2/NormalizationGM/wc1struct_brain.nii -thr 0.5000000000 -bin /tmp/tmpacrk_dhy/pipeline/_subject_id_s2/GMBinaryMask/wc1struct_brain_thresh.nii\n",
      "200630-09:48:52,474 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.NormalizationWM\".\n",
      "200630-09:48:52,843 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.NormalizationCSF\".\n",
      "200630-09:48:52,917 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.GMBinaryMask\".\n",
      "200630-09:48:54,16 nipype.workflow INFO:\n",
      "\t [Job 4] Completed (pipeline.NormalizationCSF).\n",
      "200630-09:48:54,17 nipype.workflow INFO:\n",
      "\t [Job 7] Completed (pipeline.NormalizationWM).\n",
      "200630-09:48:54,19 nipype.workflow INFO:\n",
      "\t [Job 11] Completed (pipeline.GMBinaryMask).\n",
      "200630-09:48:54,21 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 2 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Coregistration\n",
      "200630-09:48:54,307 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.CSFBinaryMask\" in \"/tmp/tmpykdzkvdq/pipeline/_subject_id_s2/CSFBinaryMask\".\n",
      "200630-09:48:54,307 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.WMBinaryMask\" in \"/tmp/tmpxhbra5hl/pipeline/_subject_id_s2/WMBinaryMask\".\n",
      "200630-09:48:54,313 nipype.workflow INFO:\n",
      "\t [Node] Running \"WMBinaryMask\" (\"nipype.interfaces.fsl.maths.Threshold\"), a CommandLine Interface with command:\n",
      "fslmaths /tmp/tmp4j2874_8/pipeline/_subject_id_s2/NormalizationWM/wc2struct_brain.nii -thr 0.5000000000 -bin /tmp/tmpxhbra5hl/pipeline/_subject_id_s2/WMBinaryMask/wc2struct_brain_thresh.nii\n",
      "200630-09:48:54,314 nipype.workflow INFO:\n",
      "\t [Node] Running \"CSFBinaryMask\" (\"nipype.interfaces.fsl.maths.Threshold\"), a CommandLine Interface with command:\n",
      "fslmaths /tmp/tmpih9t49ip/pipeline/_subject_id_s2/NormalizationCSF/wc3struct_brain.nii -thr 0.5000000000 -bin /tmp/tmpykdzkvdq/pipeline/_subject_id_s2/CSFBinaryMask/wc3struct_brain_thresh.nii\n",
      "200630-09:48:54,745 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.WMBinaryMask\".\n",
      "200630-09:48:54,747 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.CSFBinaryMask\".\n",
      "200630-09:48:56,18 nipype.workflow INFO:\n",
      "\t [Job 5] Completed (pipeline.CSFBinaryMask).\n",
      "200630-09:48:56,19 nipype.workflow INFO:\n",
      "\t [Job 8] Completed (pipeline.WMBinaryMask).\n",
      "200630-09:48:56,21 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 2 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Coregistration\n",
      "200630-09:48:56,303 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.ErosionWM\" in \"/tmp/tmpvulfzmot/pipeline/_subject_id_s2/ErosionWM\".\n",
      "200630-09:48:56,303 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.ErosionCSF\" in \"/tmp/tmpehfj_kyv/pipeline/_subject_id_s2/ErosionCSF\".\n",
      "200630-09:48:56,308 nipype.workflow INFO:\n",
      "\t [Node] Running \"ErosionWM\" (\"nipype.interfaces.fsl.maths.ErodeImage\"), a CommandLine Interface with command:\n",
      "fslmaths /tmp/tmpxhbra5hl/pipeline/_subject_id_s2/WMBinaryMask/wc2struct_brain_thresh.nii -kernel 3D -ero /tmp/tmpvulfzmot/pipeline/_subject_id_s2/ErosionWM/wc2struct_brain_thresh_ero.nii\n",
      "200630-09:48:56,312 nipype.workflow INFO:\n",
      "\t [Node] Running \"ErosionCSF\" (\"nipype.interfaces.fsl.maths.ErodeImage\"), a CommandLine Interface with command:\n",
      "fslmaths /tmp/tmpykdzkvdq/pipeline/_subject_id_s2/CSFBinaryMask/wc3struct_brain_thresh.nii -kernel 3D -ero /tmp/tmpehfj_kyv/pipeline/_subject_id_s2/ErosionCSF/wc3struct_brain_thresh_ero.nii\n",
      "200630-09:48:57,244 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.ErosionCSF\".\n",
      "200630-09:48:57,254 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.ErosionWM\".\n",
      "200630-09:48:58,19 nipype.workflow INFO:\n",
      "\t [Job 6] Completed (pipeline.ErosionCSF).\n",
      "200630-09:48:58,21 nipype.workflow INFO:\n",
      "\t [Job 9] Completed (pipeline.ErosionWM).\n",
      "200630-09:48:58,22 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Coregistration\n",
      "200630-09:54:49,440 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.Coregistration\".\n",
      "200630-09:54:50,318 nipype.workflow INFO:\n",
      "\t [Job 15] Completed (pipeline.Coregistration).\n",
      "200630-09:54:50,337 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 13.98/13.98, Free processors: 8/8.\n",
      "200630-09:54:50,677 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.Normalization\" in \"/tmp/tmps5gzaqvz/pipeline/_subject_id_s2/Normalization\".\n",
      "200630-09:54:52,323 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Normalization\n",
      "200630-09:59:07,669 nipype.workflow INFO:\n",
      "\t [Node] Running \"Normalization\" (\"nipype.interfaces.spm.preprocess.Normalize\")\n",
      "200630-10:03:37,484 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.Normalization\".\n",
      "200630-10:03:38,747 nipype.workflow INFO:\n",
      "\t [Job 16] Completed (pipeline.Normalization).\n",
      "200630-10:03:38,758 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 3 jobs ready. Free memory (GB): 13.98/13.98, Free processors: 8/8.\n",
      "200630-10:03:39,104 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.CSF_Noise_Regressors\" in \"/tmp/tmpl9ept7wi/pipeline/_subject_id_s2/CSF_Noise_Regressors\".\n",
      "200630-10:03:39,106 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.WM_Noise_Regressors\" in \"/tmp/tmpanhfhgo9/pipeline/_subject_id_s2/WM_Noise_Regressors\".\n",
      "200630-10:03:39,109 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.Smoothing\" in \"/tmp/tmpwukxcgv2/pipeline/_subject_id_s2/Smoothing\".\n",
      "200630-10:03:39,114 nipype.workflow INFO:\n",
      "\t [Node] Running \"CSF_Noise_Regressors\" (\"nipype.algorithms.confounds.CompCor\")\n",
      "200630-10:03:39,119 nipype.workflow INFO:\n",
      "\t [Node] Running \"WM_Noise_Regressors\" (\"nipype.algorithms.confounds.CompCor\")\n",
      "200630-10:03:39,121 nipype.workflow INFO:\n",
      "\t [Node] Running \"Smoothing\" (\"nipype.interfaces.spm.preprocess.Smooth\")\n",
      "200630-10:03:40,751 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 3 tasks, and 0 jobs ready. Free memory (GB): 13.38/13.98, Free processors: 5/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Smoothing\n",
      "                       * pipeline.WM_Noise_Regressors\n",
      "                       * pipeline.CSF_Noise_Regressors\n",
      "200630-10:04:00,178 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.CSF_Noise_Regressors\".\n",
      "200630-10:04:00,767 nipype.workflow INFO:\n",
      "\t [Job 17] Completed (pipeline.CSF_Noise_Regressors).\n",
      "200630-10:04:00,775 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 0 jobs ready. Free memory (GB): 13.58/13.98, Free processors: 6/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Smoothing\n",
      "                       * pipeline.WM_Noise_Regressors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200630-10:04:01,889 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.WM_Noise_Regressors\".\n",
      "200630-10:04:02,767 nipype.workflow INFO:\n",
      "\t [Job 18] Completed (pipeline.WM_Noise_Regressors).\n",
      "200630-10:04:02,769 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 1 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Smoothing\n",
      "200630-10:04:03,89 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.Design_Matrix_Gen\" in \"/tmp/tmpbrnuc37u/pipeline/_subject_id_s2/Design_Matrix_Gen\".\n",
      "200630-10:04:03,116 nipype.workflow INFO:\n",
      "\t [Node] Running \"Design_Matrix_Gen\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "200630-10:04:03,190 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.Design_Matrix_Gen\".\n",
      "200630-10:04:04,769 nipype.workflow INFO:\n",
      "\t [Job 22] Completed (pipeline.Design_Matrix_Gen).\n",
      "200630-10:04:04,771 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.Smoothing\n",
      "200630-10:04:42,52 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.Smoothing\".\n",
      "200630-10:04:42,803 nipype.workflow INFO:\n",
      "\t [Job 19] Completed (pipeline.Smoothing).\n",
      "200630-10:04:42,812 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 13.98/13.98, Free processors: 8/8.\n",
      "200630-10:04:43,183 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.GLM\" in \"/tmp/tmpikc8aewr/pipeline/_subject_id_s2/GLM\".\n",
      "200630-10:04:43,202 nipype.workflow INFO:\n",
      "\t [Node] Running \"GLM\" (\"nipype.interfaces.fsl.model.GLM\"), a CommandLine Interface with command:\n",
      "fsl_glm -i /tmp/tmpwukxcgv2/pipeline/_subject_id_s2/Smoothing/swrrafunc_roi.nii -d /tmp/tmpykqekt/DesMat.txt -o swrrafunc_roi_glm.nii --demean --des_norm -m /tmp/tmpml44z_7u/pipeline/_subject_id_s2/NormalizationMask/wstruct_brain_mask.nii --out_res=glm_res.nii\n",
      "200630-10:04:44,803 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 13.78/13.98, Free processors: 7/8.\n",
      "                     Currently running:\n",
      "                       * pipeline.GLM\n",
      "200630-10:04:55,766 nipype.workflow INFO:\n",
      "\t [Node] Finished \"pipeline.GLM\".\n",
      "200630-10:04:56,814 nipype.workflow INFO:\n",
      "\t [Job 23] Completed (pipeline.GLM).\n",
      "200630-10:04:56,826 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 13.98/13.98, Free processors: 8/8.\n",
      "200630-10:04:57,188 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"pipeline.BPF\" in \"/tmp/tmp5l708gyn/pipeline/_subject_id_s2/BPF\".\n",
      "200630-10:04:57,193 nipype.workflow INFO:\n",
      "\t [Node] Running \"BPF\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "200630-10:04:57,267 nipype.workflow WARNING:\n",
      "\t Storing result file without outputs\n",
      "200630-10:04:57,272 nipype.workflow WARNING:\n",
      "\t [Node] Error on \"pipeline.BPF\" (/tmp/tmp5l708gyn/pipeline/_subject_id_s2/BPF)\n",
      "200630-10:04:58,818 nipype.workflow ERROR:\n",
      "\t Node BPF.a0 failed to run on host udimed-H110M-R.\n",
      "200630-10:04:58,820 nipype.workflow ERROR:\n",
      "\t Saving crash info to /media/sepehr/d504ddce-3b3c-4271-a3f5-2c6dd4c230f3/Projects/GITLAB/mind_blanking/Codes/python/crash-20200630-100458-sepehr-BPF.a0-dfbc3157-7c42-4ecd-8e31-b59ef05baf51.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sepehr/anaconda3/lib/python3.7/site-packages/nipype/pipeline/plugins/multiproc.py\", line 69, in run_node\n",
      "    result['result'] = node.run(updatehash=updatehash)\n",
      "  File \"/home/sepehr/anaconda3/lib/python3.7/site-packages/nipype/pipeline/engine/nodes.py\", line 479, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/home/sepehr/anaconda3/lib/python3.7/site-packages/nipype/pipeline/engine/nodes.py\", line 585, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/home/sepehr/anaconda3/lib/python3.7/site-packages/nipype/pipeline/engine/nodes.py\", line 678, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/home/sepehr/anaconda3/lib/python3.7/site-packages/nipype/interfaces/base/core.py\", line 382, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/home/sepehr/anaconda3/lib/python3.7/site-packages/nipype/interfaces/utility/wrappers.py\", line 144, in _run_interface\n",
      "    out = function_handle(**args)\n",
      "  File \"<string>\", line 14, in bandpass_filter\n",
      "TypeError: slice indices must be integers or None or have an __index__ method\n",
      "\n",
      "200630-10:04:58,829 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 0 jobs ready. Free memory (GB): 13.98/13.98, Free processors: 8/8.\n",
      "200630-10:05:00,815 nipype.workflow INFO:\n",
      "\t ***********************************\n",
      "200630-10:05:00,817 nipype.workflow ERROR:\n",
      "\t could not run node: pipeline.BPF.a0\n",
      "200630-10:05:00,819 nipype.workflow INFO:\n",
      "\t crashfile: /media/sepehr/d504ddce-3b3c-4271-a3f5-2c6dd4c230f3/Projects/GITLAB/mind_blanking/Codes/python/crash-20200630-100458-sepehr-BPF.a0-dfbc3157-7c42-4ecd-8e31-b59ef05baf51.pklz\n",
      "200630-10:05:00,821 nipype.workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-09da416b9cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MultiProc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_procs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nipype/pipeline/plugins/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_node_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# close any open resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nipype/pipeline/plugins/tools.py\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     96\u001b[0m                             'Check log for details'))\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "res = preproc.run('MultiProc', plugin_args={'n_procs': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "desmat = '/home/sepehr/Desktop/T1_pipeline/preproc/s2/DesignMatrix/DesMat.txt'\n",
    "sig = '/home/sepehr/Desktop/T1_pipeline/preproc/s2/Smoothing/_subject_id_s2/swrrafunc_roi.nii'\n",
    "mask = ''\n",
    "\n",
    "glm2 = GLM() \n",
    "\n",
    "glm2.inputs.design = desmat \n",
    "glm2.inputs.in_file = sig \n",
    "glm2.inputs.out_res_name = 'res_test.nii'\n",
    "glm2.inputs.output_type = 'NIFTI'\n",
    "glm2.inputs.demean = True \n",
    "glm2.inputs.des_norm = True \n",
    "y = glm2.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``fsl_glm``.\n",
      "\n",
      "FSL GLM:\n",
      "\n",
      "Example\n",
      "-------\n",
      ">>> import nipype.interfaces.fsl as fsl\n",
      ">>> glm = fsl.GLM(in_file='functional.nii', design='maps.nii', output_type='NIFTI')\n",
      ">>> glm.cmdline\n",
      "'fsl_glm -i functional.nii -d maps.nii -o functional_glm.nii'\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                input file name (text matrix or 3D/4D image file)\n",
      "                argument: ``-i %s``, position: 1\n",
      "        design: (a pathlike object or string representing an existing file)\n",
      "                file name of the GLM design matrix (text time courses for temporal\n",
      "                regression or an image file for spatial regression)\n",
      "                argument: ``-d %s``, position: 2\n",
      "\n",
      "        [Optional]\n",
      "        out_file: (a pathlike object or string representing a file)\n",
      "                filename for GLM parameter estimates (GLM betas)\n",
      "                argument: ``-o %s``, position: 3\n",
      "        contrasts: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                matrix of t-statics contrasts\n",
      "                argument: ``-c %s``\n",
      "        mask: (a pathlike object or string representing an existing file)\n",
      "                mask image file name if input is image\n",
      "                argument: ``-m %s``\n",
      "        dof: (an integer (int or long))\n",
      "                set degrees of freedom explicitly\n",
      "                argument: ``--dof=%d``\n",
      "        des_norm: (a boolean)\n",
      "                switch on normalization of the design matrix columns to unit std\n",
      "                deviation\n",
      "                argument: ``--des_norm``\n",
      "        dat_norm: (a boolean)\n",
      "                switch on normalization of the data time series to unit std\n",
      "                deviation\n",
      "                argument: ``--dat_norm``\n",
      "        var_norm: (a boolean)\n",
      "                perform MELODIC variance-normalisation on data\n",
      "                argument: ``--vn``\n",
      "        demean: (a boolean)\n",
      "                switch on demeaining of design and data\n",
      "                argument: ``--demean``\n",
      "        out_cope: (a pathlike object or string representing a file)\n",
      "                output file name for COPE (either as txt or image\n",
      "                argument: ``--out_cope=%s``\n",
      "        out_z_name: (a pathlike object or string representing a file)\n",
      "                output file name for Z-stats (either as txt or image\n",
      "                argument: ``--out_z=%s``\n",
      "        out_t_name: (a pathlike object or string representing a file)\n",
      "                output file name for t-stats (either as txt or image\n",
      "                argument: ``--out_t=%s``\n",
      "        out_p_name: (a pathlike object or string representing a file)\n",
      "                output file name for p-values of Z-stats (either as text file or\n",
      "                image)\n",
      "                argument: ``--out_p=%s``\n",
      "        out_f_name: (a pathlike object or string representing a file)\n",
      "                output file name for F-value of full model fit\n",
      "                argument: ``--out_f=%s``\n",
      "        out_pf_name: (a pathlike object or string representing a file)\n",
      "                output file name for p-value for full model fit\n",
      "                argument: ``--out_pf=%s``\n",
      "        out_res_name: (a pathlike object or string representing a file)\n",
      "                output file name for residuals\n",
      "                argument: ``--out_res=%s``\n",
      "        out_varcb_name: (a pathlike object or string representing a file)\n",
      "                output file name for variance of COPEs\n",
      "                argument: ``--out_varcb=%s``\n",
      "        out_sigsq_name: (a pathlike object or string representing a file)\n",
      "                output file name for residual noise variance sigma-square\n",
      "                argument: ``--out_sigsq=%s``\n",
      "        out_data_name: (a pathlike object or string representing a file)\n",
      "                output file name for pre-processed data\n",
      "                argument: ``--out_data=%s``\n",
      "        out_vnscales_name: (a pathlike object or string representing a file)\n",
      "                output file name for scaling factors for variance normalisation\n",
      "                argument: ``--out_vnscales=%s``\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a unicode string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out_file: (a pathlike object or string representing an existing file)\n",
      "                file name of GLM parameters (if generated)\n",
      "        out_cope: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for COPEs (either as text file or image)\n",
      "        out_z: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for COPEs (either as text file or image)\n",
      "        out_t: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for t-stats (either as text file or image)\n",
      "        out_p: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for p-values of Z-stats (either as text file or\n",
      "                image)\n",
      "        out_f: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for F-value of full model fit\n",
      "        out_pf: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for p-value for full model fit\n",
      "        out_res: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for residuals\n",
      "        out_varcb: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for variance of COPEs\n",
      "        out_sigsq: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for residual noise variance sigma-square\n",
      "        out_data: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file for preprocessed data\n",
      "        out_vnscales: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                output file name for scaling factors for variance normalisation\n",
      "\n",
      "References:\n",
      "-----------\n",
      "BibTeX('@article{JenkinsonBeckmannBehrensWoolrichSmith2012,author={M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, and S.M. Smith},title={FSL},journal={NeuroImage},volume={62},pages={782-790},year={2012},}', key='JenkinsonBeckmannBehrensWoolrichSmith2012')\n"
     ]
    }
   ],
   "source": [
    "GLM.help()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
