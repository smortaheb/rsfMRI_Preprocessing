# Necessary functions for the pipeline

# Generating motion regressors using outputs of the Realignment node


def Motion_reg_creator(motion_params, outliers, N_motion_reg=12):
    # Inputs:
    # motion_params: address of a text file containing
    #                estimated motion parameters
    # outliers: address of a text file containing the label
    #           of outlier volumes
    # N_motion_reg: number of motion regressors:
    #               6 >> main 6 (translate and rotation) motion regressors
    #               12 >> main 6 motion regressors and their first-order
    #                       derivative
    #               24 >> main 6 motion regressors + their first order
    #                       derivatives + square of previous regressors
    #
    # Outputs:
    # output: a numpy array containing motion related regressors as its columns
    import numpy as np
    motpar = np.loadtxt(motion_params, dtype='f')
    out = np.loadtxt(outliers).astype(int)
    # Motion Regressors
    if N_motion_reg == 6:
        motion_reg = motpar
    elif N_motion_reg == 12:
        df = np.concatenate((np.zeros((1, 6)), np.diff(motpar, axis=0)),
                            axis=0)
        motion_reg = np.concatenate((motpar, df), axis=1)
    elif N_motion_reg == 24:
        df = np.concatenate((np.zeros((1, 6)), np.diff(motpar, axis=0)),
                            axis=0)
        motion_reg = np.concatenate((motpar, df, motpar**2, df**2), axis=1)
    # Outlier Regressors
    if len(out.shape) != 0:
        if np.shape(out)[0] != 0:
            out_reg = np.zeros((motpar.shape[0], 1))
            for i in range(len(out)):
                tmpreg = np.zeros((motpar.shape[0], 1))
                tmpreg[out[i]] = 1
                out_reg = np.concatenate((out_reg, tmpreg), axis=1)
            out_reg = out_reg[:, 1:]
            # Concatenation and creation of final motion related regressors
            output = np.concatenate((motion_reg, out_reg), axis=1)
            return output
        else:
            output = motion_reg
            return output
    else:
        output = motion_reg
        return output

# Final design matrix generator


def Design_Matrix(motion_reg, wmnoise_reg, csfnoise_reg, outliers):
    # Inputs:
    # motion_reg: a numpy array containign the motion related regressors
    #               generated by Motion_reg_creator()
    # wmnoise_reg: address of a text file containing principal components
    #                of wm time series
    # csfnoise_reg: address of a text file containing principal components
    #                of csf time seris
    # Outputs:
    # file_dir: address of a text file containing all the regressors as the
    #           design matrix
    import numpy as np
    import string
    import random
    import os
    wmnoise = np.loadtxt(wmnoise_reg, skiprows=1)
    csfnoise = np.loadtxt(csfnoise_reg, skiprows=1)
    outliers = np.loadtxt(outliers).astype(int)
    if len(outliers.shape) == 0:
        Nout = 0
    else:
        Nout = len(outliers)
    out = np.concatenate((motion_reg, wmnoise, csfnoise),
                         axis=1)
    col = out.shape[1]
    cols = np.concatenate((np.array(range(12)), np.array(range(12+Nout, col))))
    for i in cols:
        # Standardization
        tmpcol = out[:, i]
        if Nout != 0:
            rmvcol = np.delete(tmpcol, outliers)
        else:
            rmvcol = tmpcol
        M = np.mean(rmvcol)
        S = np.std(rmvcol)
        tmpcol = (tmpcol - M)/S

        if Nout != 0:
            rmvcol = np.delete(tmpcol, outliers)
        else:
            rmvcol = tmpcol
        a, b = np.polyfit(np.array(range(len(rmvcol))), rmvcol, 1)
        line = a*np.array(range(len(tmpcol)))+b
        out[:, i] = tmpcol - line
    letters = string.ascii_lowercase
    name = ''.join(random.choice(letters) for i in range(6))
    folder_dir = '/tmp/tmp'+name  # TODO: Make it more user-compatible
    os.mkdir(folder_dir)
    file_dir = folder_dir + '/DesMat.txt'
    np.savetxt(file_dir, out)
    return file_dir

# An ideal bandpass filter to apply on the fMRI time series


def bandpass_filter(signal, lowpass_freq, highpass_freq, TR):
    # Inputs:
    # signal: address of the fMRI nifti file
    # lowpass_freq: Lowpass frequency cutoff in Hz, for example 0.09 Hz
    # highpass_freq: Highpass frequency cutoff in Hz, for example 0.008 Hz
    # fs: sampling frequency in Hz calculated as 1/float(TR)
    # Outputs
    # out_files: address of the filtered fMRI nifti file
    import numpy as np
    import nibabel as nb
    from nipype.utils.filemanip import split_filename, list_to_filename
    import os
    fs = 1/float(TR)
    out_files = []
    path, name, ext = split_filename(signal)
    out_file = os.path.join(os.getcwd(), name + '_bp' + ext)
    img = nb.load(signal)
    timepoints = img.shape[-1]
    F = np.zeros((timepoints))
    lowidx = int(timepoints / 2) + 1
    if lowpass_freq > 0:
        lowidx = np.round(lowpass_freq / fs * timepoints)
    highidx = 0
    if highpass_freq > 0:
        highidx = np.round(highpass_freq / fs * timepoints)
    F[int(highidx):int(lowidx)] = 1
    F = ((F + F[::-1]) > 0).astype(int)
    data = img.get_fdata()
    if np.all(F == 1):
        filtered_data = data
    else:
        filtered_data = np.real(np.fft.ifftn(np.fft.fftn(data) * F))
    img_out = nb.Nifti1Image(filtered_data, img.affine, img.header)
    img_out.to_filename(out_file)
    out_files.append(out_file)
    return list_to_filename(out_files)

# Quality check of denoising procedure, adopted from Conn toolbox


def QC(smth_sig, den_sig, gm_mask, out_dir, sub_id, N_vox=300):
    # Inputs:
    # smth_sig: address of the preprocessed smoothed signal before denoising
    # den_sig: address of the denoised signal after regressing out nuisance
    #           confounds and bandpass filtering
    # gm_mask: address of the Grey matter mask to limit the analysis to the
    #           grey matter connectivity measures
    # out_dir: directory of the results (set in the Initialization section)
    # sub_id: Subject ID from Infosource node
    # N_vox: Number of randomly chosen voxels to calculate voxel-to-voxel
    #           connectivity measure
    # Outputs:
    # conn: list of voxel-to-voxel connectivity measures of the signal
    #       before denoising
    # connf: list of voxel-to-voxel connectivity measures of the signal
    #        after denoising
    # Also histograms of these two group of connectivity measures is saved
    # in the subject directory
    import nibabel as nb
    import numpy as np
    import matplotlib.pylab as plt
    sig = nb.load(smth_sig).get_fdata()
    sigf = nb.load(den_sig).get_fdata()
    gmmask = nb.load(gm_mask).get_fdata()
    xyz = np.where(gmmask)
    X = np.random.randint(0, len(xyz[0]), N_vox)
    Y = np.random.randint(0, len(xyz[0]), N_vox)
    conn = np.zeros(N_vox*N_vox)
    connf = np.zeros(N_vox*N_vox)
    c = 0
    for i in range(N_vox):
        for j in range(N_vox):
            x1ind = xyz[0][X[i]]
            y1ind = xyz[1][X[i]]
            z1ind = xyz[2][X[i]]
            x2ind = xyz[0][Y[j]]
            y2ind = xyz[1][Y[j]]
            z2ind = xyz[2][Y[j]]
            conn[c] = np.corrcoef(sig[x1ind, y1ind, z1ind, :],
                                  [sig[x2ind, y2ind, z2ind, :]])[0, 1]
            connf[c] = np.corrcoef(sigf[x1ind, y1ind, z1ind, :],
                                   [sigf[x2ind, y2ind, z2ind, :]])[0, 1]
            c = c+1
    plt.hist(conn, bins=100, alpha=0.6)
    plt.hist(connf, bins=100, alpha=0.6)
    plt.title('Voxel to Voxel Connectivity Histogram')
    plt.ylabel('Number of Voxel Pairs')
    plt.xlabel('Connectivity Measure (Correlation Coefficient)')
    plt.legend(('Before Denoising', 'After Denoising'))
    plt.xlim([-1, 1])
    plt.axvline(color='black', linestyle='dashed')
    plt.savefig(out_dir+'/'+sub_id+'/QC.png', dpi=300)
    return conn, connf

# Region Time Series Extraction


def roi_t_extract(atlas, img, sub_id, out_dir):
    # Inputs:
    # atlas: address of the atlas nifti file
    # img: address of the 4D functional data in the atlas space
    # sub_id: subject ID from Infosource node
    # out_dir: saving path of the output matrix
    # Outputs:
    # file_dir: address of the output matrix
    import nibabel as nb
    import numpy as np

    atlas = nb.load(atlas).get_fdata()
    img = nb.load(img).get_fdata()
    num_of_regions = len(np.unique(atlas))-1
    num_of_t = np.shape(img)[3]
    sig = np.zeros((num_of_regions, num_of_t))
    for reg in range(1, num_of_regions+1):
        idx = np.where(atlas == reg)
        sig_tmp = np.zeros((1, num_of_t))
        for i in range(len(idx[0])):
            x = idx[0][i]
            y = idx[1][i]
            z = idx[2][i]
            sig_tmp = sig_tmp+img[x, y, z, :]
        sig_tmp = sig_tmp/len(idx[0])
        sig[reg-1, :] = sig_tmp
    file_dir = out_dir+'/'+sub_id+'/Sig_file_'+sub_id+'.txt'
    np.savetxt(file_dir, sig)
    return file_dir

# Temporary files removal


def tmp_file_removal(dsink, data_dir, subj_id, file_dir):
    import os
    command1 = "rm -r "+data_dir+"/scaffoldflow/Functional"
    os.system(command1)
    command2 = "rm -r "+data_dir+"/scaffoldflow/Structural"
    os.system(command2)
    return 0

# WM and CSF Average BOLD Extraction


def mask_t_extract(mask, img):
    import numpy as np
    import nibabel as nb
    import string
    import random
    import os
    mask = nb.load(mask).get_fdata()
    img = nb.load(img).get_fdata()
    img[np.isnan(img)] = 0
    idx = np.where(mask)
    tp = img.shape[3]
    sig = np.zeros((1, tp))
    for i in range(len(idx[0])):
        x = idx[0][i]
        y = idx[1][i]
        z = idx[2][i]
        sig = sig + img[x, y, z, :]
    sig = sig/len(idx[0])
    letters = string.ascii_lowercase
    name = ''.join(random.choice(letters) for i in range(6))
    folder_dir = '/tmp/tmp'+name  # TODO: Make it more user-compatible
    os.mkdir(folder_dir)
    out_file = folder_dir + '/AvgTime.txt'
    np.savetxt(out_file, sig)
    return out_file


def detrending(sig, mask, outliers):
    import numpy as np
    import nibabel as nb
    import os

    outliers = np.loadtxt(outliers).astype(int)
    img = nb.load(sig)
    mask = nb.load(mask)

    idx = np.where(mask.dataobj)
    out = np.zeros(img.dataobj.shape)

    out_file = nb.Nifti1Image(out, img.affine, img.header)

    for i in range(len(idx[0])):
        x = idx[0][i]
        y = idx[1][i]
        z = idx[2][i]
        tmp = img.dataobj[int(x), int(y), int(z), :]
        rmvtmp = np.delete(tmp, outliers)
        a, b = np.polyfit(np.array(range(len(rmvtmp))), rmvtmp, 1)
        line = a*np.array(range(len(tmp)))+b
        out_file.dataobj[int(x), int(y), int(z), :] = tmp - line
    out_addr = os.path.join(os.getcwd(), 'detrend_image.nii')
    out_file.to_filename(out_addr)
    return out_addr




